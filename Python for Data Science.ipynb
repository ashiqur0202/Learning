{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f4e4299b-7ed2-465b-abcb-b315c61d2e3a",
   "metadata": {},
   "source": [
    "# Python for Data Science"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd777e41-a6e0-4afa-be51-b3c8edcf98c6",
   "metadata": {},
   "source": [
    "\n",
    "### Importing Data\n",
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b25f867-2815-4fe8-85aa-beb362a883b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "059473cd-b5ad-46af-904d-56126a0cf1b7",
   "metadata": {},
   "source": [
    "\n",
    "### Data Wrangling\n",
    "---\n",
    "---\n",
    "1. handling missing value\n",
    "2. data formatting\n",
    "3. data normalization\n",
    "4. data binning\n",
    "5. catagorical to numerical"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e40cce4-7db3-4eea-af6f-5b899b542b78",
   "metadata": {},
   "source": [
    "\n",
    "### Exploratory Data Analysis\n",
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14734e2d-88f5-4b89-ad79-01a27d8af3b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6a5eb89c-bd19-4eda-8ee4-5c1f7a55ea42",
   "metadata": {},
   "source": [
    "\n",
    "### Model Development\n",
    "---\n",
    "---\n",
    "1. Simple and Multiple Linear Regression\n",
    "2. Model Evaluation Using Visualization\n",
    "3. Polynomial Regression and Pipelines\n",
    "4. R-squared amd MSE for In-Sample Evaluation\n",
    "5. Prediction and Decision Making"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "147246bd-ce01-4842-aa27-19717620e478",
   "metadata": {},
   "source": [
    "---\n",
    "#### 1. Simple and Multiple Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "329193dc-697f-4aa6-8eed-8ff1452130c0",
   "metadata": {},
   "source": [
    "<b> Linear Regression\n",
    "\n",
    "> The predictor (independent) value --- x <br>\n",
    "> The target (demendent) value      --- y\n",
    "        y = b0 + b1x\n",
    "- b0=intercept\n",
    "- b1= slope\n",
    "\n",
    "Import linear_model from scikit-learn\n",
    "> from sklearn.linear_model import LinearRegression\n",
    "\n",
    "Create a linear regression object using the constructor\n",
    "> lm=LinearRegression()\n",
    "\n",
    "We define the predictor variable and target variable\n",
    "x = df[[\"column name\"]]\n",
    "y = df[[\"column name\"]]\n",
    "\n",
    "Then use lm.fit(x,y) to fit the model, i.e fine the parameters b0 and b1\n",
    "> lm.fit(x,y)\n",
    "\n",
    "We can obtain a prediction\n",
    "> yhat = lm.predict(x)\n",
    "\n",
    "<b> Multiple Linear Regression\n",
    "\n",
    "y = b0 +b1x1+b2x2+b3x3+b4x4\n",
    "- b0=intercept(x=0)\n",
    "- b1=the coefficient or parameter of x1\n",
    "- b2=the coefficient of parameter x2 and so on..\n",
    "    \n",
    "Import linear_model from scikit-learn\n",
    "> from sklearn.linear_model import LinearRegression\n",
    "\n",
    "Create a linear regression object using the constructor\n",
    "> lm=LinearRegression()\n",
    "\n",
    "We can extract the for 4 predictor variables and store them in the variable Z\n",
    "Z = df[[\"column name\", \"column name\", \"column name\",\"column name\",]]\n",
    "\n",
    "Then train the model as before:\n",
    "> lm.fit(z, df[\"column name(price)\"])\n",
    "\n",
    "We can obtain a prediction\n",
    "> yhat = lm.predict(x)\n",
    "    \n",
    "<b> MLR - Estimated Linear Model <br>\n",
    "    \n",
    "1. Find the intercept(b0) <br>\n",
    "> lm.intercept_ <br>\n",
    "    \n",
    "2. Find the coefficients(b1, b2, b3, b4) <br>\n",
    "> lm.coef_ <br>\n",
    "    \n",
    "array[[value, value, value, value]] <br>\n",
    "    \n",
    "<b> The Estimated Linear Model: <br>\n",
    "    \n",
    "Price =  <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d33cf415-6e11-487d-9428-8c4d694c78f6",
   "metadata": {},
   "source": [
    "---\n",
    "### 2. Model Evaluation Using Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80acb3c1-a35b-4fa4-be55-94ef7001dbda",
   "metadata": {},
   "source": [
    "<b> Regression Plot\n",
    "    \n",
    "import seaborn as sns <br>\n",
    "> sns.regplot(x=\"column name\", y=\"price\", data=df)\n",
    "> plt.ylim(0,)\n",
    "    \n",
    "<b> Residual Plot <br>\n",
    "import seaborn as sns\n",
    "> sns.residpolot(df[\"column name\"], df[\"price\"])\n",
    "    \n",
    "<b> Distribution Plot <br>\n",
    "import seaborn as sns\n",
    "> ax1 = sns.distplot(df[\"price\"], hist=False, color=\"r\", label=\"Actual Value\"] <br>\n",
    "> sns.distplot(yhat, hist=False, color=\"b\", label=\"Fitted Values\", ax=ax1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b63a295-1c87-4451-b3d3-0a97c527de42",
   "metadata": {},
   "source": [
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bd5f5de-94e5-4656-bc0b-35c23856b0de",
   "metadata": {},
   "source": [
    "### 3. Polynomial Regression and Pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae28d6fa-ba0e-46a0-8c6e-928175a9e30e",
   "metadata": {},
   "source": [
    "<b> Calculate Polynomial Or 3rd order\n",
    "> f=np.polyfit(x,y,3) <br>\n",
    "> p=np.polyld(f)   \n",
    "    \n",
    "<b> We can print out the model <br>\n",
    "> print (P)\n",
    "    \n",
    "<b> The \"preprocessing\" library in scikit-learn\n",
    "> from sklearn.preprocession import PolynomialFeature  <br>\n",
    "> pr=PolynomialFeature(degree=2, include_bias=False)  <br>\n",
    "> x_polly=pr.fit_transform(x[[\"column\", \"column\"]])\n",
    "    \n",
    "<b> We can normalize the each feature simultaneously\n",
    "> from sklearn.preprocession import StandardScaler  <br>\n",
    "> SCALE=StandardScaler()  <br>\n",
    "> SCALE.fit(x_data[[\"column\", \"column\"]]) <br>\n",
    "> x_scale=SCALE.transform(x_data[[\"column\", \"column\"]])    \n",
    "    \n",
    "<b> Pipeline    \n",
    "> from sklearn.preprocessing import PolynomialFeatures <br>\n",
    "> from sklearn.linear_model import LinearRegression <br>\n",
    "> from sklearn.preprocessing import StandardScaler <br>\n",
    "> from sklearn.pipeline import Pipeline <br>\n",
    "\n",
    "<b> Pipeline Constructor    \n",
    "> Input=[(\"scale\", StandardScaler()), ('polynomial', PolynomialFeatures(degree=2),...('model', LinearRegression())]\n",
    "\n",
    "<b> Train the Pipeline       \n",
    "> Pipe.fit(df[['colum', 'colum', 'colum', 'colum']],y)\n",
    "    \n",
    "<b> Predict the Pipeline       \n",
    "> yhat=Pipe.predict(x[['colum', 'colum', 'colum', 'colum']],y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "368432a6-5c49-4706-ba4a-e9751bd7b037",
   "metadata": {},
   "source": [
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e747fac-2956-4892-87c5-93d76f8a781d",
   "metadata": {},
   "source": [
    "### 4. Measures for In-Sample Evaluation\n",
    "- Mean Squared Error (MSE) - value are between 0 and 1\n",
    "- R-squared (R^2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "641d4bee-e801-405b-906e-fe911560ac52",
   "metadata": {},
   "source": [
    "<b> In Python we can measure the MSE as follows\n",
    "> from sklearn.metrics import mean_squared_error <br>\n",
    "> mean_squared_error(df[\"price\"],y_predict_simple_fit)\n",
    "\n",
    "    \n",
    "<b> We calculate the R^2 as follows\n",
    "> x = df[['column']] <br>\n",
    "> y = df['price']\n",
    "    \n",
    "> lm.fit(x,y)    \n",
    "    \n",
    "> lm.score(x,y)    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "969c5384-60f7-4d30-877f-cd31377e32d6",
   "metadata": {},
   "source": [
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0299d14-4bee-4bc4-8485-9482bfdc4d48",
   "metadata": {},
   "source": [
    "### 5. Prediction and Decision Making\n",
    "To determine final best fit, we look at a combination of:\n",
    "- Do the predicted values make sense\n",
    "- Visualization\n",
    "- Numerical measures for evaluation\n",
    "- Comparing Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb347eca-db65-48f5-9c74-a27768548e88",
   "metadata": {},
   "source": [
    "<b> Do the predicted values make sense\n",
    "First we train the model\n",
    "> lm.fit(df[\"column\", df[\"price\"])\n",
    "\n",
    "Let's predict the value\n",
    "> lm.predict(np.array(30.0).reshape(-1,1))\n",
    "    \n",
    "Result:\n",
    "> lm.coef_\n",
    "    \n",
    "> Price =     \n",
    "---    \n",
    "<b> First we import numpy   \n",
    "> import numpy as np\n",
    "    \n",
    "We use the numpy function arrange to generate a sequence from 1 to 100\n",
    "> new_input=np.arange(1,101,1).reshape(-1,1)\n",
    "    \n",
    "<b> We can predict new values\n",
    "> yhat = lm.predict(new_input)\n",
    "---  \n",
    "<b> For Decision Making follow this things:    <br>\n",
    "<b> Visualization   <br>\n",
    "<b> Regression Plot<br>\n",
    "<b> Residual Plot<br>\n",
    "<b> Distribution Plot<br>\n",
    "<b> Mean Squared Error (MSE) <br>\n",
    "<b> R-squared (R^2)   <br>\n",
    "<b>    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe628c8b-0606-4ea3-aba3-aef4f8303175",
   "metadata": {},
   "source": [
    "\n",
    "### Model Evaluation\n",
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f6eb91a-c233-4a6b-afc8-e52603150545",
   "metadata": {},
   "source": [
    "Training 70%  / Testing 30%\n",
    "\n",
    "<b> Function train_test_split()\n",
    "> c_train, x_test, y_train, y_test = train_test_split(x_data, y_data, test_size=0.3, random_state=0)\n",
    "\n",
    "<b> Cross Validation\n",
    "> from sklearn.model_selection import cross_val_score\n",
    "> score=cross_val_score(lr, x_data, y_data, cv=3)\n",
    "> np.mean(score)\n",
    "\n",
    "<b> Overfitting, Underfitting and Model Selection\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a28c807-191c-444d-8207-5e8448820ea1",
   "metadata": {},
   "source": [
    "<b> Ridge Regression\n",
    "> from sklearn.linear_model import Ridge\n",
    "> RidgeModel=Ridge(alpha=0.1) <br>\n",
    "> RidgeModel.fit(x,y)\n",
    "\n",
    "> yhat=RidgeModel.predict(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "993c2c13-8519-42b9-9b20-5871e68a9015",
   "metadata": {},
   "source": [
    "<b> Grid Search\n",
    "> from sklearn.kinear_model import Ridge <br>\n",
    "    from sklearn.model_selection import GridSearchCV <br>\n",
    "    \n",
    ">   parameters1=[{'alpha':[0.0001, 0.1, 100, 1000]}] <br>\n",
    "    RR=Ridge()\n",
    "    \n",
    ">   Grid1=GridSearchCV(RR, parameters1, cv=4) <br>\n",
    "    grid1.fit(x_data[['horsepower','curb-weight','engine-size']],y_data) <br>\n",
    "    Grid1.best_estimator_\n",
    "    \n",
    ">   scores=Grid1.cv_results_ <br>\n",
    "    SCORE['mean_test_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24991e13-6303-4176-8372-59cb6008136d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "068e3caa-7519-4a67-8f3f-197903a13b68",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "345ffbee-4de3-4c19-9b82-e6b1450d77c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f21406b4-47e6-45f0-a77d-1fd1d981923a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
